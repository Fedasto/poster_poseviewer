<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>ArUco Pose Viewer (mobile-friendly)</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<style>
  body { font-family: sans-serif; background: #111; color: #fff; text-align: center; margin:0; padding:20px; }
  video, canvas { width: 90vw; max-width: 600px; border-radius:8px; background:#000; }
  #info { margin-top: 12px; white-space: pre; font-size: 14px; }
  #startBtn { margin: 12px; padding: 10px 16px; font-size:16px; border-radius:8px; }
</style>
</head>
<body>

<h2>ArUco Pose Viewer</h2>

<!-- Start button helps on iOS where a user gesture is sometimes required -->
<button id="startBtn">Start Camera</button>
<br>
<video id="video" playsinline autoplay muted></video>
<canvas id="canvas"></canvas>
<div id="info">Initializing...</div>

<script>
let video = document.getElementById('video');
let canvas = document.getElementById('canvas');
let ctx = canvas.getContext('2d');
let info = document.getElementById('info');

let detector;
let initialized = false;
let cameraMatrix, distCoeffs;

// Use ideal environment camera, but allow fallback
async function initCamera() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: { ideal: "environment" } },
      audio: false
    });
    video.srcObject = stream;
    // Return a promise that resolves when video metadata is loaded
    return new Promise((resolve, reject) => {
      video.onloadedmetadata = () => {
        // In some browsers you need to call play() explicitly
        video.play().then(()=>resolve()).catch(reject);
      };
      // fallback timeout
      setTimeout(() => {
        if (video.videoWidth > 0) resolve();
        else reject(new Error("Timed out waiting for video metadata"));
      }, 3000);
    });
  } catch (err) {
    throw err;
  }
}

function onOpenCVReady() {
    console.log("OpenCV.js loaded");
    cv['onRuntimeInitialized'] = async () => {
        console.log("OpenCV runtime initialized");
        await startApplication();
    };
}

async function startApplication() {
    info.textContent = "Loading camera...";
    try {
        await initCamera();

        // create aruco detector (uses predefined dictionary)
        detector = new cv.aruco.Dictionary(cv.aruco.getPredefinedDictionary(cv.aruco.DICT_4X4_50));

        // Now video.videoWidth & video.videoHeight should be available
        let w = video.videoWidth || 640;
        let h = video.videoHeight || 480;
        // A simple focal length estimate â€” use width as baseline
        let f = Math.max(w, h);
        cameraMatrix = cv.matFromArray(3,3,cv.CV_64F, [
            f, 0, w/2,
            0, f, h/2,
            0, 0, 1
        ]);
        distCoeffs = cv.Mat.zeros(5,1,cv.CV_64F);

        info.textContent = "Point your camera at the ArUco marker.";
        initialized = true;
        tick();
    } catch (error) {
        console.error(error);
        info.textContent = "Camera error: " + (error && error.message ? error.message : error);
    }
}

function tick() {
    if (!initialized || !cv) {
        requestAnimationFrame(tick);
        return;
    }

    // adjust canvas size to video
    canvas.width = video.videoWidth || canvas.width;
    canvas.height = video.videoHeight || canvas.height;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    let src = cv.imread(canvas);
    let gray = new cv.Mat();
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

    let corners = new cv.MatVector();
    let ids = new cv.Mat();

    // detect markers
    cv.aruco.detectMarkers(gray, detector, corners, ids);

    if (!ids.empty()) {
        cv.aruco.drawDetectedMarkers(src, corners, ids);

        let rvec = new cv.Mat();
        let tvec = new cv.Mat();

        cv.aruco.estimatePoseSingleMarkers(
            corners,
            0.10, // marker length meters (adjust as needed)
            cameraMatrix,
            distCoeffs,
            rvec, tvec
        );

        for (let i = 0; i < ids.rows; i++) {
            // draw axis for each marker
            let rvecRow = new cv.Mat();
            let tvecRow = new cv.Mat();
            rvec.row(i).copyTo(rvecRow);
            tvec.row(i).copyTo(tvecRow);
            cv.aruco.drawAxis(src, cameraMatrix, distCoeffs, rvecRow, tvecRow, 0.05);
            rvecRow.delete(); tvecRow.delete();
        }

        // show first marker pose
        if (rvec.data64F && rvec.data64F.length >= 3 && tvec.data64F && tvec.data64F.length >= 3) {
            let r = [rvec.data64F[0].toFixed(3), rvec.data64F[1].toFixed(3), rvec.data64F[2].toFixed(3)];
            let t = [tvec.data64F[0].toFixed(3), tvec.data64F[1].toFixed(3), tvec.data64F[2].toFixed(3)];
            info.textContent = "Marker ID: " + ids.data32S[0] + "\n" +
                "rvec: [" + r.join(", ") + "]\n" +
                "tvec: [" + t.join(", ") + "]";
        }

        rvec.delete(); tvec.delete();
    } else {
        info.textContent = "No markers detected";
    }

    cv.imshow(canvas, src);
    src.delete(); gray.delete(); corners.delete(); ids.delete();

    requestAnimationFrame(tick);
}

document.addEventListener('DOMContentLoaded', function() {
    info.textContent = "Loading OpenCV...";
    // Start button for iOS / explicit permission
    document.getElementById('startBtn').addEventListener('click', async () => {
        document.getElementById('startBtn').style.display = 'none';
        // If OpenCV already loaded runtime may already call startApplication, otherwise onOpenCVReady will trigger it.
        if (typeof cv !== 'undefined' && cv && cv['onRuntimeInitialized']) {
            // if OpenCV ready, startApplication will be called by onRuntimeInitialized
        } else {
            // fallback:
            onOpenCVReady();
        }
    });
});

// Load OpenCV; page will call onOpenCVReady when script is loaded
</script>
<script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCVReady()"></script>

</body>
</html>
